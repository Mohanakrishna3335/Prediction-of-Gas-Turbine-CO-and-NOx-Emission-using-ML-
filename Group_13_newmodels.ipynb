{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2714912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "259a486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>0.32663</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>0.44784</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>0.23107</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>0.26747</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>10.99300</td>\n",
       "      <td>89.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>11.14400</td>\n",
       "      <td>88.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>11.41400</td>\n",
       "      <td>96.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>3.31340</td>\n",
       "      <td>64.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>11.98100</td>\n",
       "      <td>109.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "             CO      NOX  \n",
       "0       0.32663   81.952  \n",
       "1       0.44784   82.377  \n",
       "2       0.45144   83.776  \n",
       "3       0.23107   82.505  \n",
       "4       0.26747   82.028  \n",
       "...         ...      ...  \n",
       "36728  10.99300   89.172  \n",
       "36729  11.14400   88.849  \n",
       "36730  11.41400   96.147  \n",
       "36731   3.31340   64.738  \n",
       "36732  11.98100  109.240  \n",
       "\n",
       "[36733 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Group_13_data_cleaned.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7b937",
   "metadata": {},
   "source": [
    "# For NOx as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3152f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine\n",
    "#For NOX as target variable \n",
    "nox_df = df.copy()\n",
    "nox_df = nox_df.drop(\"CO\", axis = 1) # drop the target variable CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac01ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>89.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>88.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>96.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>64.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>109.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "           NOX  \n",
       "0       81.952  \n",
       "1       82.377  \n",
       "2       83.776  \n",
       "3       82.505  \n",
       "4       82.028  \n",
       "...        ...  \n",
       "36728   89.172  \n",
       "36729   88.849  \n",
       "36730   96.147  \n",
       "36731   64.738  \n",
       "36732  109.240  \n",
       "\n",
       "[36733 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22afb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# split the data \n",
    "X = nox_df.iloc[:, :-1]\n",
    "y = nox_df[\"NOX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2025e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the X and y. As we removed Outliers in Part1 we are not going to Standardize instead we are performing normalizing \n",
    "X = nox_df = Normalizer().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772a492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle= False)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42,shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7b89d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22039, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272b34d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7347, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f58af92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7347, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420aa36",
   "metadata": {},
   "source": [
    "# Kernel(Non Linear SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b993b403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2621a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 7.876\n",
      "MSE on train set is: 114.34\n",
      "RMSE on the train set: 10.692978314151583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics \n",
    "y_train_pred = regressor.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cb20dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on valid set: 10.087\n",
      "MSE on valid set is: 143.139\n",
      "RMSE on the valid set: 11.964091358345728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics \n",
    "y_pred = regressor.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6f9ad",
   "metadata": {},
   "source": [
    "# Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b45a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='poly')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel=\"poly\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f13794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 7.325\n",
      "MSE on train set is: 98.694\n",
      "RMSE on the train set: 9.934506108645387\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_poly = model.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred_poly)\n",
    "mse = mean_squared_error(y_train, y_train_pred_poly)\n",
    "rmse = mean_squared_error(y_train, y_train_pred_poly, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bce717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on valid set: 9.872\n",
      "MSE on valid set is: 132.63\n",
      "RMSE on the valid set: 11.516530418851197\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217b818",
   "metadata": {},
   "source": [
    "# Checking Model hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ed14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 42, shuffle = True)\n",
    "score_valid = cross_val_score(regressor, X_train, y_train, scoring = 'r2', cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d99ce29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07903234, 0.0771833 , 0.06896878, 0.07221034, 0.06912432,\n",
       "       0.05487865, 0.07396259, 0.0671921 , 0.07220805, 0.07592668])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a708ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07106871500730723\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "995d37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV , cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecaa0f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12142\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid={'C': [100],'gamma': [ 1],'kernel': [ 'rbf']},\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2aaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hyper = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9ab801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 5.973\n",
      "MSE on test set is: 73.222\n",
      "RMSE on the test set: 8.557012573102769\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_hyper)\n",
    "mse = mean_squared_error(y_test, y_pred_hyper)\n",
    "rmse = mean_squared_error(y_test, y_pred_hyper, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ff29a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44744359437249237"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0534d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 8.904\n",
      "MSE on test set is: 126.909\n",
      "RMSE on the test set: 11.265392174850925\n"
     ]
    }
   ],
   "source": [
    "# Rbf kernel\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "895fb2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 8.526\n",
      "MSE on test set is: 114.64\n",
      "RMSE on the test set: 10.706984761969485\n"
     ]
    }
   ],
   "source": [
    "#Poly kernel\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c001d",
   "metadata": {},
   "source": [
    "# For CO as target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5166d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CO as target variable \n",
    "# prepare the data for the model\n",
    "# select the only NOX as target variabel\n",
    "co_df = df.copy()\n",
    "co_df = co_df.drop(\"NOX\", axis = 1) # drop the target variable NOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "162d7ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>0.32663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>0.44784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>0.45144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>0.23107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>0.26747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>10.99300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>11.14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>11.41400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>3.31340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>11.98100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "             CO  \n",
       "0       0.32663  \n",
       "1       0.44784  \n",
       "2       0.45144  \n",
       "3       0.23107  \n",
       "4       0.26747  \n",
       "...         ...  \n",
       "36728  10.99300  \n",
       "36729  11.14400  \n",
       "36730  11.41400  \n",
       "36731   3.31340  \n",
       "36732  11.98100  \n",
       "\n",
       "[36733 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93382338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# split the data \n",
    "X = co_df.iloc[:, :-1]\n",
    "y = co_df[\"CO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25f4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data \n",
    "X = co_df = Normalizer().fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d19935aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle= False)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d2d8157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a18e98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 0.905\n",
      "MSE on train set is: 3.325\n",
      "RMSE on the train set: 1.8234558203381892\n",
      "MAE on valid set: 0.773\n",
      "MSE on valid set is: 2.759\n",
      "RMSE on the valid set: 1.6611474804346456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics \n",
    "y_train_pred = regressor.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")\n",
    "\n",
    "y_pred = regressor.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "398772bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='poly')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel=\"poly\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6068ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 0.881\n",
      "MSE on train set is: 3.059\n",
      "RMSE on the train set: 1.7491395100313678\n",
      "MAE on valid set: 0.802\n",
      "MSE on valid set is: 2.64\n",
      "RMSE on the valid set: 1.6249095504283737\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_poly = model.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred_poly)\n",
    "mse = mean_squared_error(y_train, y_train_pred_poly)\n",
    "rmse = mean_squared_error(y_train, y_train_pred_poly, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43783aaf",
   "metadata": {},
   "source": [
    "# Model Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee9b2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 42, shuffle = True)\n",
    "score_valid = cross_val_score(regressor, X_train, y_train, scoring = 'r2', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff31ac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43097338, 0.38852413, 0.40258649, 0.38911638, 0.37523125,\n",
       "       0.418979  , 0.3410746 , 0.29764237, 0.39426569, 0.31997352])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da08c4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3758366804288669\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fb45136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV , cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f43bc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12142\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid={'C': [100],'gamma': [10],'kernel': [ 'rbf']},\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ff9307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hyper = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15fb20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 0.731\n",
      "MSE on test set is: 2.474\n",
      "RMSE on the test set: 1.5728448665946315\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_hyper)\n",
    "mse = mean_squared_error(y_test, y_pred_hyper)\n",
    "rmse = mean_squared_error(y_test, y_pred_hyper, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc3ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5450521942041706"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4a25c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 0.951\n",
      "MSE on test set is: 3.659\n",
      "RMSE on the test set: 1.912905952559538\n"
     ]
    }
   ],
   "source": [
    "# Rbf kernel\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0899af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 0.931\n",
      "MSE on test set is: 3.379\n",
      "RMSE on the test set: 1.838230958676243\n"
     ]
    }
   ],
   "source": [
    "#Poly kernel\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce7512",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "562d3df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>0.32663</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>0.44784</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>0.23107</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>0.26747</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>10.99300</td>\n",
       "      <td>89.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>11.14400</td>\n",
       "      <td>88.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>11.41400</td>\n",
       "      <td>96.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>3.31340</td>\n",
       "      <td>64.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>11.98100</td>\n",
       "      <td>109.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "             CO      NOX  \n",
       "0       0.32663   81.952  \n",
       "1       0.44784   82.377  \n",
       "2       0.45144   83.776  \n",
       "3       0.23107   82.505  \n",
       "4       0.26747   82.028  \n",
       "...         ...      ...  \n",
       "36728  10.99300   89.172  \n",
       "36729  11.14400   88.849  \n",
       "36730  11.41400   96.147  \n",
       "36731   3.31340   64.738  \n",
       "36732  11.98100  109.240  \n",
       "\n",
       "[36733 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db04e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00287537, 0.63846307, 0.05244272, ..., 0.34460209, 0.08440348,\n",
       "        0.00745699],\n",
       "       [0.0026911 , 0.63830015, 0.05280096, ..., 0.34478739, 0.08441509,\n",
       "        0.00745425],\n",
       "       [0.00244676, 0.63818101, 0.05317632, ..., 0.34477691, 0.0846605 ,\n",
       "        0.00754613],\n",
       "       ...,\n",
       "       [0.00350102, 0.65684029, 0.06081057, ..., 0.34708757, 0.06885168,\n",
       "        0.00668144],\n",
       "       [0.00368636, 0.64451993, 0.05901991, ..., 0.34466497, 0.0823334 ,\n",
       "        0.00737498],\n",
       "       [0.00380076, 0.64747277, 0.05950292, ..., 0.34502721, 0.07892648,\n",
       "        0.00721358]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32cc6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine\n",
    "#For NOX as target variable \n",
    "nox_df = df.copy()\n",
    "nox_df = nox_df.drop(\"CO\", axis = 1) # drop the target variable CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b7aa917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>89.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>88.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>96.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>64.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>109.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "           NOX  \n",
       "0       81.952  \n",
       "1       82.377  \n",
       "2       83.776  \n",
       "3       82.505  \n",
       "4       82.028  \n",
       "...        ...  \n",
       "36728   89.172  \n",
       "36729   88.849  \n",
       "36730   96.147  \n",
       "36731   64.738  \n",
       "36732  109.240  \n",
       "\n",
       "[36733 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d510af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# split the data \n",
    "X = nox_df.iloc[:, :-1]\n",
    "y = nox_df[\"NOX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3df1a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the X and y. As we removed Outliers in Part1 we are not going to Standardize instead we are performing normalizing \n",
    "X = nox_df = Normalizer().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82988967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle =False)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c4b14",
   "metadata": {},
   "source": [
    "# Performing Linear SVM Model for NOx as Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43b7961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10, kernel='linear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'linear', C=10)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6127887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 7.438\n",
      "MSE on train set is: 101.616\n",
      "RMSE on the train set: 10.080481312454648\n",
      "MAE on valid set: 9.93\n",
      "MSE on valid set is: 134.931\n",
      "RMSE on the valid set: 11.615971738828925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics \n",
    "y_train_pred = regressor.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")\n",
    "\n",
    "y_pred = regressor.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e5fbcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 10.89\n",
      "MSE on test set is: 159.307\n",
      "RMSE on the test set: 12.621668854700836\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176803a",
   "metadata": {},
   "source": [
    "# Model Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94136209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 42, shuffle = True)\n",
    "score_valid = cross_val_score(regressor, X_train, y_train, scoring = 'r2', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42896de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17114358, 0.17198834, 0.15664678, 0.16387687, 0.15805171,\n",
       "       0.14435097, 0.16465591, 0.15805589, 0.16124459, 0.16927311])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dd7bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16192877540003348\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f7cbf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12142\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid={'C': [10],'gamma': [1],'kernel': [ 'linear']},\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c16a7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hyper = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "036daa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 7.943\n",
      "MSE on test set is: 109.351\n",
      "RMSE on the test set: 10.457079577889035\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_hyper)\n",
    "mse = mean_squared_error(y_test, y_pred_hyper)\n",
    "rmse = mean_squared_error(y_test, y_pred_hyper, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "accc4d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17481162015794072"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5044ab",
   "metadata": {},
   "source": [
    "## EXTREME LEARNING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1342d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Scikit-ELM in c:\\users\\12142\\anaconda3\\lib\\site-packages (0.21a0)\n",
      "Requirement already satisfied: numpy in c:\\users\\12142\\anaconda3\\lib\\site-packages (from Scikit-ELM) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\12142\\anaconda3\\lib\\site-packages (from Scikit-ELM) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\12142\\anaconda3\\lib\\site-packages (from Scikit-ELM) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\12142\\anaconda3\\lib\\site-packages (from scikit-learn->Scikit-ELM) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\12142\\anaconda3\\lib\\site-packages (from scikit-learn->Scikit-ELM) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Scikit-ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6822564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Defining input and output variables\n",
    "X = nox_df.iloc[:, :-1]\n",
    "y = nox_df[\"NOX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c8b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29386, 9), (7347, 9), (29386,), (7347,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 42, shuffle = True)\n",
    "X_train.shape ,X_test.shape,y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd629932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c41c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skelm import ELMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a3510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELM_1 = ELMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "622e2bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ELMRegressor()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data \n",
    "ELM_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0408daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the output values\n",
    "ELM_y_pred = ELM_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab78e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "rs_ELM_mae1 = mean_absolute_error(y_test, ELM_y_pred)\n",
    "# calculating mean squared error\n",
    "rs_ELM_mse1 = mean_squared_error(y_test, ELM_y_pred)\n",
    "# calculating r2 score\n",
    "rs_ELM_r_score_1 = r2_score(y_test, ELM_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17c2f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mae_1: 4.202518460787809\n",
      " mse_1: 34.92072827159142\n",
      " r_score_1: 0.7364787935953266\n"
     ]
    }
   ],
   "source": [
    "print(f' mae_1: {rs_ELM_mae1}')\n",
    "print(f' mse_1: {rs_ELM_mse1}')\n",
    "print(f' r_score_1: {rs_ELM_r_score_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5721929",
   "metadata": {},
   "source": [
    "## Using Hyperparameters for NOx as Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ff9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized searchcv to tune the  hyper parameters.\n",
    "rs_ELM_1 = RandomizedSearchCV(estimator = ELMRegressor(random_state=42),\n",
    "                  param_distributions= {\"n_neurons\": [10,20,50,80],\n",
    "                                \"ufunc\": ['tanh', 'sigm', 'relu', 'lin'],\n",
    "                                \"alpha\" : [1e-07,1e-05,1e-01],\n",
    "                                },\n",
    "                  cv=5,\n",
    "                  n_iter=25,\n",
    "                  scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ELM_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c30167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best metrics of y\n",
    "print(\"The best score of the model is:\",rs_ELM_1.best_score_)\n",
    "print(\"The best parameters of the model are:\", rs_ELM_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ELM_y1_pred = rs_ELM_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee044c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ELM_mae1 = mean_absolute_error(y_test,rs_ELM_y1_pred)\n",
    "# calculating mean squared error\n",
    "rs_ELM_mse1 = mean_squared_error(y_test,rs_ELM_y1_pred)\n",
    "# calculating r2 score\n",
    "rs_ELM_r_score_1 = r2_score(y_test,rs_ELM_y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb45bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' mae_1: {rs_ELM_mae1}')\n",
    "print(f' mse_1: {rs_ELM_mse1}')\n",
    "print(f' r_score_1: {rs_ELM_r_score_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da0cf1",
   "metadata": {},
   "source": [
    "# Performing Linear SVM model for CO as Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0555a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CO as target variable \n",
    "# prepare the data for the model\n",
    "# select the only NOX as target variable\n",
    "co_df = df.copy()\n",
    "co_df = co_df.drop(\"NOX\", axis = 1) # drop the target variable NOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ca05e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.898</td>\n",
       "      <td>0.32663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.892</td>\n",
       "      <td>0.44784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>135.10</td>\n",
       "      <td>12.042</td>\n",
       "      <td>0.45144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>135.03</td>\n",
       "      <td>11.990</td>\n",
       "      <td>0.23107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>134.67</td>\n",
       "      <td>11.910</td>\n",
       "      <td>0.26747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36728</th>\n",
       "      <td>3.6268</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>93.200</td>\n",
       "      <td>3.1661</td>\n",
       "      <td>19.087</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>541.59</td>\n",
       "      <td>109.08</td>\n",
       "      <td>10.411</td>\n",
       "      <td>10.99300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36729</th>\n",
       "      <td>4.1674</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>94.036</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>19.016</td>\n",
       "      <td>1037.6</td>\n",
       "      <td>542.28</td>\n",
       "      <td>108.79</td>\n",
       "      <td>10.344</td>\n",
       "      <td>11.14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36730</th>\n",
       "      <td>5.4820</td>\n",
       "      <td>1028.5</td>\n",
       "      <td>95.219</td>\n",
       "      <td>3.3128</td>\n",
       "      <td>18.857</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>543.48</td>\n",
       "      <td>107.81</td>\n",
       "      <td>10.462</td>\n",
       "      <td>11.41400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36731</th>\n",
       "      <td>5.8837</td>\n",
       "      <td>1028.7</td>\n",
       "      <td>94.200</td>\n",
       "      <td>3.9831</td>\n",
       "      <td>23.563</td>\n",
       "      <td>1076.9</td>\n",
       "      <td>550.11</td>\n",
       "      <td>131.41</td>\n",
       "      <td>11.771</td>\n",
       "      <td>3.31340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36732</th>\n",
       "      <td>6.0392</td>\n",
       "      <td>1028.8</td>\n",
       "      <td>94.547</td>\n",
       "      <td>3.8752</td>\n",
       "      <td>22.524</td>\n",
       "      <td>1067.9</td>\n",
       "      <td>548.23</td>\n",
       "      <td>125.41</td>\n",
       "      <td>11.462</td>\n",
       "      <td>11.98100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36733 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  134.67  11.898   \n",
       "1      4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  134.67  11.892   \n",
       "2      3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  135.10  12.042   \n",
       "3      3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  135.03  11.990   \n",
       "4      3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  134.67  11.910   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "36728  3.6268  1028.5  93.200  3.1661  19.087  1037.0  541.59  109.08  10.411   \n",
       "36729  4.1674  1028.6  94.036  3.1923  19.016  1037.6  542.28  108.79  10.344   \n",
       "36730  5.4820  1028.5  95.219  3.3128  18.857  1038.0  543.48  107.81  10.462   \n",
       "36731  5.8837  1028.7  94.200  3.9831  23.563  1076.9  550.11  131.41  11.771   \n",
       "36732  6.0392  1028.8  94.547  3.8752  22.524  1067.9  548.23  125.41  11.462   \n",
       "\n",
       "             CO  \n",
       "0       0.32663  \n",
       "1       0.44784  \n",
       "2       0.45144  \n",
       "3       0.23107  \n",
       "4       0.26747  \n",
       "...         ...  \n",
       "36728  10.99300  \n",
       "36729  11.14400  \n",
       "36730  11.41400  \n",
       "36731   3.31340  \n",
       "36732  11.98100  \n",
       "\n",
       "[36733 rows x 10 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9067e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# split the data \n",
    "X = co_df.iloc[:, :-1]\n",
    "y = co_df[\"CO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7bbeafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data \n",
    "X = co_df = Normalizer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f8f2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb6cbd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'linear')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab98d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on train set: 0.979\n",
      "MSE on train set is: 3.712\n",
      "RMSE on the train set: 1.926544859037334\n",
      "MAE on valid set: 0.971\n",
      "MSE on valid set is: 3.501\n",
      "RMSE on the valid set: 1.8710639904550126\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = regressor.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "print(\"MAE on train set:\", round (mae, 3))\n",
    "print(\"MSE on train set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the train set: {np.sqrt(mse)}\")\n",
    "\n",
    "y_pred = regressor.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "print(\"MAE on valid set:\", round (mae, 3))\n",
    "print(\"MSE on valid set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the valid set: {np.sqrt(mse)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bf082",
   "metadata": {},
   "source": [
    "# Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2300f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV , cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 42, shuffle = True)\n",
    "score_valid = cross_val_score(regressor, X_train, y_train, scoring = 'r2', cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "774e8431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33819749, 0.30288442, 0.31584116, 0.30181466, 0.29390431,\n",
       "       0.32540329, 0.26193666, 0.2335808 , 0.30584782, 0.24620395])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d99cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2925614566589133\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53944a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12142\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid={'C': [100],'gamma': [ 1],'kernel': ['linear']},\n",
    "grid_search = GridSearchCV(estimator=model,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7bce5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hyper = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0876ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 0.88\n",
      "MSE on test set is: 3.086\n",
      "RMSE on the test set: 1.7566534357706647\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred_hyper)\n",
    "mse = mean_squared_error(y_test, y_pred_hyper)\n",
    "rmse = mean_squared_error(y_test, y_pred_hyper, squared=False)\n",
    "print(\"MAE on test set:\", round (mae, 3))\n",
    "print(\"MSE on test set is:\", round(mse, 3))\n",
    "print(f\"RMSE on the test set: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25333b3d",
   "metadata": {},
   "source": [
    "### ELM For CO as Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47d30cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data for training and test using sklearn train_test_split function \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "X = co_df.iloc[:, :-1]\n",
    "y = co_df[\"CO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8574a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.3,random_state= 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "563db98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELM_2 = ELMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b78f708b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ELMRegressor()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data \n",
    "ELM_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2101f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the output values\n",
    "ELM_y2_pred = ELM_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7442f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "ELM_mae2 = mean_absolute_error(y_test,ELM_y2_pred)\n",
    "# calculating mean squared error\n",
    "ELM_mse2 = mean_squared_error(y_test,ELM_y2_pred)\n",
    "# calculating r2 score\n",
    "ELM_r_score_2 = r2_score(y_test,ELM_y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4aa06f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mae_2: 1.0339424513916213\n",
      " mse_2: 3.024960217499189\n",
      " r_score_2: 0.3946362136120509\n"
     ]
    }
   ],
   "source": [
    "print(f' mae_2: {ELM_mae2}')\n",
    "print(f' mse_2: {ELM_mse2}')\n",
    "print(f' r_score_2: {ELM_r_score_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d6287",
   "metadata": {},
   "source": [
    "## Using Hyperparameters for CO as Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fd4484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c741441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized searchcv to tune the  hyper parameters.\n",
    "rs_ELM_2 = RandomizedSearchCV(estimator = ELMRegressor(random_state=42),\n",
    "                  param_distributions= {\"n_neurons\": [10,20,50,80],\n",
    "                                \"ufunc\": ['tanh', 'sigm', 'relu', 'lin'],\n",
    "                                \"alpha\" : [1e-07,1e-05,1e-01],\n",
    "                                },\n",
    "                  cv=5,\n",
    "                  n_iter=25,\n",
    "                  scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d56ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=ELMRegressor(random_state=42), n_iter=25,\n",
       "                   param_distributions={'alpha': [1e-07, 1e-05, 0.1],\n",
       "                                        'n_neurons': [10, 20, 50, 80],\n",
       "                                        'ufunc': ['tanh', 'sigm', 'relu',\n",
       "                                                  'lin']},\n",
       "                   scoring='r2')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_ELM_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d601a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score of the model is: 0.5727558973409004\n",
      "The best parameters of the model are: {'ufunc': 'relu', 'n_neurons': 80, 'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# best metrics of y\n",
    "print(\"The best score of the model is:\",rs_ELM_2.best_score_)\n",
    "print(\"The best parameters of the model are:\", rs_ELM_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2de8e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ELM_y2_pred = rs_ELM_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "419e0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "ELM_mae2 = mean_absolute_error(y_test,ELM_y2_pred)\n",
    "# calculating mean squared error\n",
    "ELM_mse2 = mean_squared_error(y_test,ELM_y2_pred)\n",
    "# calculating r2 score\n",
    "ELM_r_score_2 = r2_score(y_test,ELM_y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50263b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean squared error\n",
    "rs_ELM_mse2 = mean_squared_error(y_test,rs_ELM_y2_pred)\n",
    "# calculating r2 score\n",
    "rs_ELM_r_score_2 = r2_score(y_test,rs_ELM_y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ad6dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mae_2: 1.0339424513916213\n",
      " mse_2: 2.08555666426542\n",
      " r_score_2: 0.5826323692778701\n"
     ]
    }
   ],
   "source": [
    "print(f' mae_2: {ELM_mae2}')\n",
    "print(f' mse_2: {rs_ELM_mse2}')\n",
    "print(f' r_score_2: {rs_ELM_r_score_2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
